1.3b:
  adam_beta1: 0.9
  adam_beta2: 0.95
  batch_size: 1000000
  block_size: 2048
  d_heads: 64
  d_model: 2048
  dropout_prob: 0.1
  global_gradient_norm: 1.0
  learning_rate_decay: 0.1
  max_learning_rate: 2.0e-05
  n_heads: 32
  n_layers: 24
  name_suffix: 1.3b
  vocab_size: 50000
  warmup_steps: 500
  weight_decay: 0.1
125m:
  adam_beta1: 0.9
  adam_beta2: 0.95
  batch_size: 32
  block_size: 2048
  d_heads: 64
  d_model: 768
  dropout_prob: 0.1
  global_gradient_norm: 1.0
  learning_rate_decay: 0.1
  max_learning_rate: 5.9999999999999995e-05
  n_heads: 12
  n_layers: 12
  name_suffix: 125m
  vocab_size: 50000
  warmup_steps: 500
  weight_decay: 0.1
6.7b:
  adam_beta1: 0.9
  adam_beta2: 0.95
  batch_size: 2000000
  block_size: 2048
  d_heads: 128
  d_model: 4096
  dropout_prob: 0.1
  global_gradient_norm: 1.0
  learning_rate_decay: 0.1
  max_learning_rate: 1.2e-05
  n_heads: 32
  n_layers: 32
  name_suffix: 6.7b
  vocab_size: 50000
  warmup_steps: 500
  weight_decay: 0.1
small_opt:
  adam_beta1: 0.9
  adam_beta2: 0.95
  batch_size: 2
  block_size: 2048
  dropout_prob: 0.1
  ffn_dim: 16
  global_gradient_norm: 1.0
  hidden_size: 16
  learning_rate_decay: 0.1
  max_learning_rate: 5.9999999999999995e-05
  max_position_embeddings: 2048
  name_suffix: 125m
  num_attention_heads: 1
  num_hidden_layers: 1
  vocab_size: 50000
  warmup_steps: 500
  weight_decay: 0.1
  word_embed_proj_dim: 16
