{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from accelerate import init_empty_weights, Accelerator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hrant/chem/tigran/ChemLactica/checkpoints/facebook/galactica-125m/ac7915df73b24ee3a4e172d6/checkpoint-253952'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = '/home/hrant/chem/tigran/ChemLactica/checkpoints/facebook'\n",
    "model_size = 'galactica-125m'\n",
    "run_hash = 'ac7915df73b24ee3a4e172d6'\n",
    "checkpoint_no = 'checkpoint-253952'\n",
    "checkpoint_path = os.path.join(base_path, model_size, run_hash, checkpoint_no)\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to a free GPU device for faster inference\n",
    "device = \"cuda:5\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_hash = 'dff5ace8f2ac45cc9681ab6a'\n",
    "# checkpoint_no = 'checkpoint-194560'\n",
    "# checkpoint_path = os.path.join(base_path, model_size, run_hash, checkpoint_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer size:  50029\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer/ChemLacticaTokenizer/\")\n",
    "print('tokenizer size: ', len(tokenizer))\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, torch_dtype=torch.bfloat16)\n",
    "model.to(device)\n",
    "assert(model.model.decoder.embed_tokens.num_embeddings + 1 == len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"</s>[QED 0.84][START_SMILES]\"\"\"\n",
    "prompt = \"\"\"</s>[SAS 4.32][START_SMILES]\"\"\"\n",
    "prompt = \"\"\"</s>[TPSA 4.32][START_SMILES]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to cast a BatchEncoding to type torch.bfloat16. This is not supported.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "inputs = inputs.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>[TPSA 4.32][START_SMILES]CC1=CC(=C(C=C1)C)N2C(=O)C3=C(C2=O)C=C(C=C3)Br[END_SMILES][CID 17131262][NUMROTATABLEBONDS 1][SAS 1.86][IUPAC 5-bromo-2-(2,5-dimethylphenyl)isoindole-1,3-dione][NUMAROMATICRINGS 2][WEIGHT 330.0][NHOHCOUNT 0][NUMSATURATEDRINGS 0][NUMALIPHATICHETEROCYCLES 1][RINGCOUNT 3][NUMAROMATICCARBOCYCLES 2][NUMALIPHATICRINGS 1][NUMSATURATEDHETEROCYCLES 0][NUMHDONORS 0][NUMALIPHATICCARBOCYCLES 0][HEAVYATOMCOUNT 20][NUMHETEROATOMS 4][NUMHACCEPTORS 2][FRACTIONCSP3 0.13][NOCOUNT 3][QED 0.75][CLOGP 3.8][NUMAROMATICHETEROCYCLES 0][NUMSATURATEDCARBOCYCLES 0]</s>']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(inputs.input_ids, max_new_tokens=300, do_sample=True, top_k=1, top_p=0.95)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import rdkit.Chem as Chem\n",
    "import sys\n",
    "from rdkit.Chem import RDConfig, MACCSkeys\n",
    "import numpy as np \n",
    "def tanimoto_similarity(smiles_1, smiles_2):\n",
    "    fgp1 = np.array(MACCSkeys.GenMACCSKeys(Chem.MolFromSmiles(smiles_1)))\n",
    "    fgp2 = np.array(MACCSkeys.GenMACCSKeys(Chem.MolFromSmiles(smiles_2)))\n",
    "\n",
    "    both = np.sum(fgp1 & fgp2)\n",
    "\n",
    "    return both / (np.sum(fgp1) + np.sum(fgp2) - both)\n",
    "sys.path.append(os.path.join(RDConfig.RDContribDir, 'SA_Score'))\n",
    "import sascorer\n",
    "mol_source = Chem.MolFromSmiles(\"CC1=C(C(=C(C(=C1C)C)C2=C(C(=C(C(=C2C)C)C3=C(C(=C(C(=C3C)C)C)C)C)C)C)C)C\")\n",
    "mol_second = Chem.MolFromSmiles(\"CC1=CC(=C(C=C1)C)C(=C)C2=CC=CC=C2C\")\n",
    "source_sas = sascorer.calculateScore(mol_source)\n",
    "print(tanimoto_similarity(\"CC1=C(C(=C(C(=C1C)C)C2=C(C(=C(C(=C2C)C)C3=C(C(=C(C(=C3C)C)C)C)C)C)C)C)C\",\"CC1=CC(=C(C=C1)C)C(=C)C2=CC=CC=C2C\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
